\documentclass[letterpaper, 10 pt, conference]{ieeeconf} 
\IEEEoverridecommandlockouts 
\overrideIEEEmargins                                      % Needed to meet printer requirements.
\usepackage{natbib}


\title{\LARGE \bf
Interpreting Multimodal Referring Expressions in Real Time}
\author{Miles Eldon$^{1}$ and Stefanie Tellex$^{1}$
\thanks{$^{1}$Computer Science Department, Brown University}
}

\usepackage{amsfonts, amssymb, amsmath}
\usepackage[usenames,dvipsnames]{color}
\newcommand{\stnote}[1]{\textcolor{Blue}{\textbf{ST: #1}}}
\newcommand{\menote}[1]{\textcolor{Red}{\textbf{ME: #1}}}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\begin{abstract}
Identifying objects for shared tasks, such as a knife for assistance
at cooking, or a screw used to assemble a part on a factory floor, is
a key part of many human-robot collaborative tasks.  Robots that
collaborate with people must be able to understand their references to
objects in the environment.  Existing work has addressed this problem
in single modalities, such as natural language or gesture, but a gap
remains in creating real-time multimodal systems that simultaneously
fuse information from language and gesture in a principled mathemtical
framework.  We define a multimodal Bayes' filtering approach to
interpreting referring expressions to object using language and
gesture.  We collected a new RGB-D and audio dataset of people
referring to objects in a tabletop setting and demonstrate that our
approach successfully integrates information from language and gesture
in real time to quickly and accurately identify objects.
\end{abstract}

\section{INTRODUCTION}

\section{RELATED WORK}


\citep{matuszek12}

\section{TECHNICAL APPROACH}

Our aim is to estimate a distribution over the object that a person is
referring to given language and gesture inputs.  We frame the problem
as a Bayes' filter, where the hidden state, $\mathcal{X}$, is the set
of $m$ objects in the scene that can be referenced and a state for no
item being referenced.  The robot observes the person's actions and
speech, $\mathcal{Z}$, and at each timestep estimates a distribution
over $\mathcal{X}$:
\begin{align}
  p(\mathcal{X}_t | \mathcal{Z}_0 \dots \mathcal{Z}_{0:t})
\end{align}


\stnote{Time update and measurement update should go here, with z and
  not the tuple.  Then the observation model section should explain
  how each model works.}



The time update is the probability that the person will change the
object they are referring to at the next time step:
\begin{align}
P(x_t | \mathcal{Z}_{0:t-1}) = 
\end{align}
\stnote{Should be an integral over the previous state}


The measurement update incorporates an estimate of the updated state
based on new observations of the person's actions: 
\begin{align}
P(x_t | \mathcal{Z}_{0:t}) \
\end{align}
\stnote{Should be Bayes's rule.}





\subsection{Observation Model}

We assume access to an observation model of the form:
\begin{align}
p(z_t | x_t)
\end{align}

Observations consist of a tuple consisting of a person's actions,
$\langle l, r, h, s\rangle $ where:
\begin{itemize}
	\item $l$ represents the observed origin ($l_o$) and vector ($l_v$) for the left arm.
	\item $r$ represents the observed origin  ($r_o$) and vector ($r_v$)  for the right arm .
	\item $h$ represents the observed origin  ($h_o$) and vector ($h_v$)  for head.
	\item $s$ represents the observed speech from the user, consisting of a list of words.
	\end{itemize}

\begin{align}
p(z_t | x_t) = p(l, r, h, s | x_t)\\
p(z_t | x_t) = p(l | x_t) \times p(r | x_t) \times p(h | x_t) \times p(s | x_t)
\end{align}

{\bf Gesture.}  We model gesture ....

\stnote{Fill in equations here}

{\bf Head Pose.}

\stnote{Fill in equations here}

{\bf Speech.}

\stnote{Fill in equations here}



\begin{itemize}
\item{Transition Function}
	\begin{itemize}
	\item{$\mathcal{T}$: a function such that $\mathcal{T}(x_a, x_b)$ is equivalent to the probability that $x_a$ transitions to $x_b$}
	\item{\stnote{Model with Poisson?}}
	\end{itemize}

\item{$\Phi$: a function that, given an origin and two points, returns the angle between the two points}
	\begin{itemize}
	\item{Applied as $\Phi(\text{origin}, p_1, p_2)$}
	\end{itemize}
\item{$\mathcal{I}$: an indicator function applied as $\mathcal{I}(\text{word}, \text{corpus}$ that returns 1 if the word is in the corpus and 0 otherwise}
\item{$len$: the number of items in a list}
%\item{$\mu_l$, $\mu_r$, \mu_h$: the sample means for each component of the observations}
%\item{$\sigma_l$, $\sigma_r$, $\sigma_h$: the sample variances for each component of the observations}
\end{itemize}
\textbf{Equations}
\begin{itemize}
\item{Time Update}
	\begin{itemize}
	\item{An equation used to determine the probability that $\mathcal{X}_t = x$ given only previous belief states}
	\item{$P(\mathcal{X}_t = x | \mathcal{X}_{t-1} .... \mathcal{X}_0) =\displaystyle\sum_{x' \in \mathcal{X}} \mathcal{T}(x, x')*bel(\mathcal{X}_{t-1} = x')$}
	\item{This function computes the new probability for a state by multiplying the probability for each past state times  transition probability and then summing all these new probabilities.}
	\end{itemize}
\item{Measurement Update}
	\begin{itemize}
	\item{An equation used to determine the belief that $\mathcal{X}_t = x$ given observation $\mathcal{Z}_{t-1}$}
	\item{$P(\mathcal{X}_t=x | \mathcal{Z}_{t-1}) = P(X_t=x | l_{t-1})*P(X_t=x | r_{t-1})*P(X_t=x |h_{t-1})*P(X_t=x | s_{t-1})$}
	\item{$P(\mathcal{X}_t=x|l_{t-1}) = [\displaystyle \prod_{p \in x_p} \mathcal{N}(\mu_l=0, \sigma_l, \Phi(l_o,l_v, p))]^{(\frac{\sum_{x'\in\mathcal{X}} len(x'_p)}{len(x_p)})}$\\}
	\item{$P(\mathcal{X}_t=x|r_{t-1}) = [\displaystyle \prod_{p \in x_p} \mathcal{N}(\mu_r=0, \sigma_r, \Phi(r_o,r_v, p))]^{(\frac{\sum_{x'\in\mathcal{X}} len(x'_p)}{len(x_p)})}$\\}
	\item{$P(\mathcal{X}_t=x|h_{t-1}) = [\displaystyle \prod_{p \in x_p} \mathcal{N}(\mu_h=0, \sigma_h, \Phi(h_o,h_v, p))]^{(\frac{\sum_{x'\in\mathcal{X}} len(x'_p)}{len(x_p)})}$\\}
	\item{These three equations are all very similar. They basically compute the probability of each point being seen given the vector of the gesture and multiply this out for all points. Finally, it is raised to a power equal to the ratio of total points to the number of points in the given object to normalize so that small objects don't have much larger probabilities.}
	\item{$P(\mathcal{X}_t=x|s_{t-1}) = \frac{\displaystyle\sum_{w\in s_{t-1}} \mathcal{I}(w, x_d)}{\displaystyle\sum_{x \in \mathcal{X}}\sum_{w\in s_{t-1}} \mathcal{I}(w, x'_d)}$}
	\item{This simply computes the ratio of words in the spoken phrase that are in the descriptors of the object to the number of the words that match any object}
	\end{itemize}
\item{Belief Update}
	\begin{itemize}
	\item{An equation that produces the probability that $\mathcal{X}_t = x$ given all past observations and belief states, namely the product of the measurement and time updates}
	\item{$bel(X_t = x) = P(\mathcal{X}_t=x | \mathcal{Z}_{t-1})*P(\mathcal{X}_t = x | \mathcal{X}_{t-1} .... \mathcal{X}_0)$}
	\item{$bel(\mathcal{X}_0 = x) =  \frac{1}{m+1}$ (uniform initialization of belief)}
	\end{itemize}
\end{itemize}

\section{EVALUATION}

\section{CONCLUSION}

\section{REFERENCES}
\bibliographystyle{abbrvnat}
\bibliography{main}



\end{document}
