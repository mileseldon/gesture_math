\documentclass[letterpaper, 10 pt, conference]{ieeeconf} 
\IEEEoverridecommandlockouts 
\overrideIEEEmargins                                      % Needed to meet printer requirements.
\usepackage{natbib}


\title{\LARGE \bf
Interpreting Multimodal Referring Expressions in Real Time}
\author{Miles Eldon$^{1}$ and Stefanie Tellex$^{1}$
\thanks{$^{1}$Computer Science Department, Brown University}
}

\usepackage{amsfonts, amssymb, amsmath}
\usepackage[usenames,dvipsnames]{color}
\newcommand{\stnote}[1]{\textcolor{Blue}{\textbf{ST: #1}}}
\newcommand{\menote}[1]{\textcolor{Red}{\textbf{ME: #1}}}

\begin{document}

\maketitle
\thispagestyle{empty}
\pagestyle{empty}

\begin{abstract}
Identifying objects for shared tasks, such as a knife for assistance
at cooking, or a screw used to assemble a part on a factory floor, is
a key part of many human-robot collaborative tasks.  Robots that
collaborate with people must be able to understand their references to
objects in the environment.  Existing work has addressed this problem
in single modalities, such as natural language or gesture, but a gap
remains in creating real-time multimodal systems that simultaneously
fuse information from language and gesture in a principled mathemtical
framework.  We define a multimodal Bayes' filtering approach to
interpreting referring expressions to object using language and
gesture.  We collected a new RGB-D and audio dataset of people
referring to objects in a tabletop setting and demonstrate that our
approach successfully integrates information from language and gesture
in real time to quickly and accurately identify objects.
\end{abstract}

\section{INTRODUCTION}

\section{RELATED WORK}


\citep{matuszek12}

\section{TECHNICAL APPROACH}
\menote{Is there a place I should define variables or should I just define as they come up?}
Our aim is to estimate a distribution over the object that a person is
referring to given language and gesture inputs.  We frame the problem
as a Bayes' filter, where the hidden state, $\mathcal{X}$, is the set
of $m$ objects in the scene that can be referenced and a state for no
item being referenced.  The robot observes the person's actions and
speech, $\mathcal{Z}$, and at each timestep estimates a distribution
over $\mathcal{X}$:
\begin{align}
  p(\mathcal{X}_t | \mathcal{Z}_0 \dots \mathcal{Z}_{0:t})
\end{align}




The time update is the probability that the person will change the
object they are referring to at the next time step:
\begin{align}
p(x_t | \mathcal{Z}_{0:t-1}) = \int p(x_t|x_{t-1})\times p(x_{t-1} | \mathcal{Z}_{0:t-1}) \text{d}x_{t-1}
\end{align}

The measurement update incorporates an estimate of the updated state
based on new observations of the person's actions: 
\begin{align}
p(x_t | \mathcal{Z}_{0:t}) = \frac{p(\mathcal{Z}_t | x_t) \times p(x_t | \mathcal{Z}_{0:t-1})}{p(\mathcal{Z}_t | \mathcal{Z}_{0:t-1})} \\\propto p(\mathcal{Z}_t | x_t) \times p(x_t | \mathcal{Z}_{0:t-1})
\end{align}





\subsection{Observation Model}

We assume access to an observation model of the form:
\begin{align}
p(z_t | x_t)
\end{align}

Observations consist of a tuple consisting of a person's actions,
$\langle l, r, h, s\rangle $ where:
\begin{itemize}
	\item $l$ represents the observed origin ($l_o$) and vector ($l_v$) for the left arm.
	\item $r$ represents the observed origin  ($r_o$) and vector ($r_v$)  for the right arm .
	\item $h$ represents the observed origin  ($h_o$) and vector ($h_v$)  for head.
	\item $s$ represents the observed speech from the user, consisting of a list of words.
	\end{itemize}

\begin{align}
p(z_t | x_t) = p(l, r, h, s | x_t)\\
p(z_t | x_t) = p(l | x_t) \times p(r | x_t) \times p(h | x_t) \times p(s | x_t)
\end{align}
\menote{time subscript on l, r, h, and s?}

{\bf Gesture.}  We model gesture as a vector through three dimensional space. We calculate the probability of a gesture by examining every three dimensional particle (denoted as $q$) in an object and calculating the angle between the vector and the vector formed with that particle. We then use a Gaussian distribution with a  variance found during training to calculate the probability of seeing that angle difference. We then take the product of each of these points and normalize it. The probability of each gesture given the state is as follows:
\begin{align}
p(l|x_t) = [\displaystyle \prod_{q \in x_t} \mathcal{N}(\mu_l=0, \sigma_l, \Phi(l_o,l_v, q))]^{(\frac{\sum_{x'\in\mathcal{X}} len(x'_p)}{len(x_p)})}\\
p(r|x_t) = [\displaystyle \prod_{q \in x_t} \mathcal{N}(\mu_r=0, \sigma_r, \Phi(r_o,r_v, q))]^{(\frac{\sum_{x'\in\mathcal{X}} len(x'_p)}{len(x_p)})}
\end{align}
{\bf Head Pose.}
Head pose is modeled in the same manner as arm gestures.
\begin{align}
p(h|x_t) = [\displaystyle \prod_{q \in x_t} \mathcal{N}(\mu_h=0, \sigma_h, \Phi(h_o,h_v, q))]^{(\frac{\sum_{x'\in\mathcal{X}} len(x'_p)}{len(x_p)})}
\end{align}
\menote{More concise way to show this? They are all the same besides variance. I guess we could just do $\prod_{g\in\{h,l,r\}}$}
{\bf Speech.}
We model speech with a simple bag of words model. We take the words in a given speech input and count how many words in this text match descriptors (denoted  $x_d$) of specific objects.
\begin{align}
p(s_t |\mathcal{X}_t=x) = \frac{\displaystyle\sum_{w\in s_{t}} \mathcal{I}(w, x_d)}{\displaystyle\sum_{x \in \mathcal{X}}\sum_{w\in s_{t}} \mathcal{I}(w, x'_d)}
\end{align}
\menote{This is only the case if we just have a set of descriptors without counts/probabilities. If we want to gain sample descriptors from user then we should probably use Bayesian classification}



\begin{itemize}
\item{Transition Function}
	\begin{itemize}
	\item{$\mathcal{T}$: a function such that $\mathcal{T}(x_a, x_b)$ is equivalent to the probability that $x_a$ transitions to $x_b$}
	\item{\stnote{Model with Poisson?}}
	\end{itemize}

\item{$\Phi$: a function that, given an origin and two points, returns the angle between the two points}
	\begin{itemize}
	\item{Applied as $\Phi(\text{origin}, p_1, p_2)$}
	\end{itemize}
\item{$\mathcal{I}$: an indicator function applied as $\mathcal{I}(\text{word}, \text{corpus}$ that returns 1 if the word is in the corpus and 0 otherwise}
\item{$len$: the number of items in a list}
%\item{$\mu_l$, $\mu_r$, \mu_h$: the sample means for each component of the observations}
%\item{$\sigma_l$, $\sigma_r$, $\sigma_h$: the sample variances for each component of the observations}
\end{itemize}
\textbf{Equations}
\begin{itemize}
\item{Time Update}
	\begin{itemize}
	\item{An equation used to determine the probability that $\mathcal{X}_t = x$ given only previous belief states}
	\item{$P(\mathcal{X}_t = x | \mathcal{X}_{t-1} .... \mathcal{X}_0) =\displaystyle\sum_{x' \in \mathcal{X}} \mathcal{T}(x, x')*bel(\mathcal{X}_{t-1} = x')$}
	\item{This function computes the new probability for a state by multiplying the probability for each past state times  transition probability and then summing all these new probabilities.}
	\end{itemize}
\item{Measurement Update}
	\begin{itemize}
	\item{An equation used to determine the belief that $\mathcal{X}_t = x$ given observation $\mathcal{Z}_{t-1}$}
	\item{$P(\mathcal{X}_t=x | \mathcal{Z}_{t-1}) = P(X_t=x | l_{t-1})*P(X_t=x | r_{t-1})*P(X_t=x |h_{t-1})*P(X_t=x | s_{t-1})$}
	\item{$P(\mathcal{X}_t=x|l_{t-1}) = [\displaystyle \prod_{p \in x_p} \mathcal{N}(\mu_l=0, \sigma_l, \Phi(l_o,l_v, p))]^{(\frac{\sum_{x'\in\mathcal{X}} len(x'_p)}{len(x_p)})}$\\}
	\item{$P(\mathcal{X}_t=x|r_{t-1}) = [\displaystyle \prod_{p \in x_p} \mathcal{N}(\mu_r=0, \sigma_r, \Phi(r_o,r_v, p))]^{(\frac{\sum_{x'\in\mathcal{X}} len(x'_p)}{len(x_p)})}$\\}
	\item{$P(\mathcal{X}_t=x|h_{t-1}) = [\displaystyle \prod_{p \in x_p} \mathcal{N}(\mu_h=0, \sigma_h, \Phi(h_o,h_v, p))]^{(\frac{\sum_{x'\in\mathcal{X}} len(x'_p)}{len(x_p)})}$\\}
	\item{These three equations are all very similar. They basically compute the probability of each point being seen given the vector of the gesture and multiply this out for all points. Finally, it is raised to a power equal to the ratio of total points to the number of points in the given object to normalize so that small objects don't have much larger probabilities.}
	\item{$P(\mathcal{X}_t=x|s_{t-1}) = \frac{\displaystyle\sum_{w\in s_{t-1}} \mathcal{I}(w, x_d)}{\displaystyle\sum_{x \in \mathcal{X}}\sum_{w\in s_{t-1}} \mathcal{I}(w, x'_d)}$}
	\item{This simply computes the ratio of words in the spoken phrase that are in the descriptors of the object to the number of the words that match any object}
	\end{itemize}
\item{Belief Update}
	\begin{itemize}
	\item{An equation that produces the probability that $\mathcal{X}_t = x$ given all past observations and belief states, namely the product of the measurement and time updates}
	\item{$bel(X_t = x) = P(\mathcal{X}_t=x | \mathcal{Z}_{t-1})*P(\mathcal{X}_t = x | \mathcal{X}_{t-1} .... \mathcal{X}_0)$}
	\item{$bel(\mathcal{X}_0 = x) =  \frac{1}{m+1}$ (uniform initialization of belief)}
	\end{itemize}
\end{itemize}

\section{EVALUATION}

\section{CONCLUSION}

\section{REFERENCES}
\bibliographystyle{abbrvnat}
\bibliography{main}



\end{document}
